import logging
from datetime import datetime
from deep_research.agent import create_agent

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DeepResearchService:
    def __init__(self, llm, search_engine):
        logger.info("ğŸ”¬ Initializing DeepResearchService...")
        logger.info(f"  LLM: {llm.model_name if hasattr(llm, 'model_name') else type(llm)}")
        logger.info(f"  Search engine: {type(search_engine)}")
        # ä¿å­˜åŸå§‹ llm å’Œæœç´¢å¼•æ“ï¼Œç»™ç®€æ´ç‰ˆ RAG ä½¿ç”¨
        self.llm = llm
        self.search_engine = search_engine

        # åˆ›å»ºå®Œæ•´ç‰ˆ RAG çš„ agent
        self.agent = create_agent(llm, search_engine)
        logger.info("âœ… DeepResearchService initialized")
        
    def run(self, query: str, mode: str = "rag") -> str:
        logger.info(f"ğŸš€ Starting deep research for query: {query[:100]}...")
        if mode == "rag":
            return self.simple_rag(query)

        initial_agent_state = {
            'date': datetime.now().strftime('%Y-%m-%d'),
            'search_num': 3,
            'question': query,
        }
        logger.info(f"ğŸ“‹ Initial agent state: date={initial_agent_state['date']}, search_num={initial_agent_state['search_num']}")
        
        try:
            logger.info("ğŸ”„ Invoking LangGraph agent...")
            final_state = self.agent.invoke(initial_agent_state)
            logger.info(f"âœ… Agent completed. Final state keys: {list(final_state.keys())}")
            
            answer = final_state.get('final_answer', "No answer generated by the agent.")
            logger.info(f"ğŸ“ Final answer length: {len(answer)} characters")
            
            # Log any errors
            if 'error' in final_state and final_state['error']:
                logger.warning(f"âš ï¸  Agent reported error: {final_state['error']}")
            
            return answer
        except Exception as e:
            logger.error(f"âŒ Deep research agent failed: {e}", exc_info=True)
            raise

    # ===== ç®€æ´ç‰ˆ RAGï¼šLLM -> keywords -> æœç´¢å¼•æ“ -> LLM æ€»ç»“ =====

    def _generate_search_keywords(self, question: str, max_keywords: int = 3) -> list[str]:
        """
        ä½¿ç”¨ LLM ä»é—®é¢˜é‡ŒæŠ½å–å°‘é‡æ£€ç´¢å…³é”®è¯ã€‚
        è¿”å›å…³é”®è¯åˆ—è¡¨ï¼Œä¾‹å¦‚ ["Apple iPhone é”€é‡ 2024", "Apple Vision Pro å¸‚åœºåé¦ˆ"]
        """
        prompt = (
            "ä½ æ˜¯æœç´¢å…³é”®è¯ç”ŸæˆåŠ©æ‰‹ã€‚\n"
            "è¯·æ ¹æ®ä¸‹é¢çš„ç”¨æˆ·é—®é¢˜ï¼Œç”Ÿæˆä¸è¶…è¿‡ "
            f"{max_keywords} ç»„é€‚ç”¨äºé€šç”¨æœç´¢å¼•æ“çš„æŸ¥è¯¢å…³é”®è¯ï¼Œ"
            "å°½é‡è¦†ç›–é—®é¢˜ä¸­çš„å…³é”®ä¿¡æ¯ï¼ˆå“ç‰Œã€äº§å“ã€æ—¶é—´ã€å¸‚åœºã€é£é™©ç­‰ï¼‰ã€‚\n"
            "åªè¾“å‡ºå…³é”®è¯ï¼Œç”¨ç«–çº¿ '|' åˆ†éš”ï¼Œä¸è¦è¾“å‡ºå…¶å®ƒè¯´æ˜æ–‡å­—ã€‚\n\n"
            f"ç”¨æˆ·é—®é¢˜ï¼š{question}\n\n"
            "è¾“å‡ºç¤ºä¾‹ï¼š\n"
            "Apple iPhone 15 é”€é‡ 2024|Apple Vision Pro ç”¨æˆ·åé¦ˆ\n"
        )

        # ChatOpenAI æ”¯æŒç›´æ¥ç”¨å­—ç¬¦ä¸² prompt
        resp = self.llm.invoke(prompt)
        if hasattr(resp, "content"):
            text = resp.content.strip()
        else:
            text = str(resp).strip()

        # æŒ‰ | æ‹†åˆ†å…³é”®è¯ï¼Œå»æ‰ç©ºç™½
        keywords = [kw.strip() for kw in text.split("|") if kw.strip()]
        return keywords[:max_keywords] if keywords else [question]

    def _search_with_keywords(self, keywords: list[str]) -> str:
        """
        ç”¨ SearxSearchWrapper å¯¹æ¯ä¸ªå…³é”®è¯æœç´¢ï¼Œå¹¶æŠŠç»“æœæ‹¼åœ¨ä¸€èµ·è¿”å›ã€‚
        è¿™é‡Œä½¿ç”¨ search_engine.run()ï¼Œå®ƒä¼šè¿”å›ä¸€ä¸ªæ±‡æ€»å­—ç¬¦ä¸²ã€‚
        """
        logger.info(f"ğŸ” Simple RAG æœç´¢å…³é”®è¯: {keywords}")
        snippets: list[str] = []
        for kw in keywords:
            try:
                result = self.search_engine.run(kw)  # SearxSearchWrapper çš„ç®€æ´æ¥å£
                snippets.append(f"ã€æœç´¢ï¼š{kw}ã€‘\n{result}")
            except Exception as e:
                logger.warning(f"æœç´¢ '{kw}' å¤±è´¥: {e}")
        return "\n\n".join(snippets)

    def simple_rag(self, question: str, max_keywords: int = 3) -> str:
        """
        ç®€æ´ç‰ˆ RAG æµç¨‹ï¼š
        1. ç”¨ LLM ç”Ÿæˆæœç´¢å…³é”®è¯
        2. ç”¨ Searx æœç´¢ï¼Œæ‹¿åˆ°èšåˆæ–‡æœ¬
        3. ç”¨ LLM å¯¹è¿™äº›æœç´¢ç»“æœè¿›è¡Œæ€»ç»“ï¼Œç›´æ¥å›ç­”é—®é¢˜
        """
        logger.info(f"ğŸš€ Simple RAG for question: {question[:100]}")

        # 1. ç”Ÿæˆæœç´¢å…³é”®è¯
        keywords = self._generate_search_keywords(question, max_keywords=max_keywords)
        logger.info(f"ğŸ”‘ ç”Ÿæˆçš„æœç´¢å…³é”®è¯: {keywords}")

        # 2. æœç´¢å¼•æ“æ£€ç´¢
        search_text = self._search_with_keywords(keywords)
        if not search_text:
            logger.warning("âš ï¸ Simple RAG æœç´¢ç»“æœä¸ºç©ºï¼Œç›´æ¥ç”¨ LLM å†…éƒ¨çŸ¥è¯†å›ç­”")
            search_text = "(æœªä»ç½‘ç»œæ£€ç´¢åˆ°æœ‰æ•ˆä¿¡æ¯)"

        # 3. ç”¨ LLM æ€»ç»“
        summary_prompt = (
            "ä½ æ˜¯ä¸€ä¸ªç®€æ´ã€å¯é çš„ç ”ç©¶åŠ©æ‰‹ã€‚\n"
            "æˆ‘ä¼šç»™ä½ ä¸€ä¸ªç”¨æˆ·é—®é¢˜ï¼Œä»¥åŠåŸºäºæœç´¢å¼•æ“å¾—åˆ°çš„ä¸€äº›åŸå§‹èµ„æ–™ç‰‡æ®µã€‚\n"
            "è¯·åŸºäºè¿™äº›èµ„æ–™ï¼ŒæŒ‰å¦‚ä¸‹è¦æ±‚å›ç­”é—®é¢˜ï¼š\n"
            "1. å›ç­”è¦å›´ç»•ç”¨æˆ·é—®é¢˜ï¼Œåªæ€»ç»“èµ„æ–™ä¸­èƒ½æ”¯æŒçš„ç»“è®ºï¼Œä¸è¦è‡†æµ‹ã€‚\n"
            "2. å¦‚æœèµ„æ–™ä¸­ä¿¡æ¯æœ‰é™ï¼Œè¯·æ˜ç¡®è¯´æ˜ä¸ç¡®å®šæˆ–ç¼ºå¤±çš„éƒ¨åˆ†ã€‚\n"
            "3. å°½é‡ç»“æ„åŒ–è¾“å‡ºï¼Œä½¿ç”¨ç®€çŸ­æ®µè½æˆ–åˆ—è¡¨ã€‚\n\n"
            f"ã€ç”¨æˆ·é—®é¢˜ã€‘\n{question}\n\n"
            f"ã€æœç´¢èµ„æ–™ã€‘\n{search_text}\n\n"
            "ç°åœ¨è¯·ç»™å‡ºç»¼åˆæ€§çš„ä¸­æ–‡å›ç­”ï¼š"
        )

        resp = self.llm.invoke(summary_prompt)
        if hasattr(resp, "content"):
            answer = resp.content.strip()
        else:
            answer = str(resp).strip()

        logger.info(f"ğŸ“ Simple RAG answer length: {len(answer)} characters")
        return answer